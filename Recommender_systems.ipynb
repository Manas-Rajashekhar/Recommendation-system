{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Recommender systems.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJkUsp0Or2P7"
      },
      "source": [
        "\n",
        "### Recommndation systems using Matrix factorization , Bayesian Personalised ranking and Alternation Least squares optimization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hufl4MYxr2P7"
      },
      "source": [
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np                               # loading ll necessary libraries \n",
        "import implicit\n",
        "import scipy.sparse as sparse\n",
        "from scipy.sparse.linalg import spsolve\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjDRXGTIr2P7"
      },
      "source": [
        "# loading datasets\n",
        "df_train   = pd.read_csv(\"train_data.csv\")\n",
        "df_test = pd.read_csv(\"test_data.csv\")\n",
        "#df_test \n",
        "#df_train.head()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGuuBfOGr2P7"
      },
      "source": [
        "Once we load the data sets , we get a list of unique user_id's and item_id's which will later be useful to create a dataframe for this challenge"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3aWYHwCyr2P8"
      },
      "source": [
        "users = list(df_train.user_id.unique())              # get a unique list of users and items \n",
        "items = list(df_train.item_id.unique())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDIBawbGr2P8"
      },
      "source": [
        "To create  sparse matrices reprsenting user features and item features , we make use of scipy package "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOIvqJ1fr2P8"
      },
      "source": [
        " #Contruct a sparse matrix for our users and items containing number of plays\n",
        "user_sparse_data = sparse.csr_matrix((df_train['rating'],(df_train['user_id'],df_train['item_id'])))\n",
        "item_sparse_data = sparse.csr_matrix((df_train['rating'],(df_train['item_id'],df_train['user_id'])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SPy9mFkr2P8"
      },
      "source": [
        "##### Auxillary  Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjZvq_Qgr2P8"
      },
      "source": [
        "\n",
        "def get_recommendations(x):\n",
        "    '''This function takes input x (user_id) and returns all recommendations of items with respective scores '''\n",
        "                                 # model_1  - ALS , model_2 - Bayesian , model_3 - Logistic Matrix Factorization\n",
        "    user_id = x                           \n",
        "    recommended = model_1.recommend(user_id, user_sparse_data,N=len(items)) # get  all items with respective scores \n",
        "    return recommended\n",
        "\n",
        "\n",
        "def check_list(x):\n",
        "    '''\n",
        "    This function returns takes in user_id as input and returns all items for a user in the test data set\n",
        "    '''\n",
        "    user_id = x\n",
        "    check_items = df_test[df_test['user_id'] == user_id]       # subset test dataframe based on user and return all 100 items in testd dataset\n",
        "    check_list=check_items['item_id'].values\n",
        "    return check_list\n",
        "\n",
        "\n",
        "def top_recommendations(x):\n",
        "    '''\n",
        "    Takes in user_id as input returns top 10 recomendations based on highest scores.  \n",
        "    \n",
        "    '''\n",
        "    h_items =[]                              # declare empty list to store top items \n",
        "    b= get_recommendations(x)                # call function to get all (items, score) with their score in descending order \n",
        "    a = check_list(x)                        # list of all 100 items in test data\n",
        "    for i,j in b:                            \n",
        "        if i in a:                           # for each user get top 10 based on their score by iterating of list of users\n",
        "            h_items.append(i)\n",
        "    h_items = h_items[0:10]\n",
        "    return h_items\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFx6Z6jor2P8"
      },
      "source": [
        "#top_recommendations(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49F8S6Qbr2P8"
      },
      "source": [
        "#### Model 1 : Alternating Least Squares (ALS model) \n",
        "\n",
        "This famous algorithm is known to work well for implicit data . We  make use of implicit library to call the inbuilt recommender model.Alternating Least Square (ALS) is  a matrix factorization algorithm "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "1c7d47865d434e8dab872eecbc8bd278"
          ]
        },
        "id": "IMOTn5_mr2P8",
        "outputId": "0bf359b4-180f-438a-d774-db8b3a95deee"
      },
      "source": [
        "#Building and fitting the model\n",
        "\n",
        "model_1= implicit.als.AlternatingLeastSquares(factors=8, regularization=0.1, iterations=45)\n",
        "alpha = 37\n",
        "data = ( item_sparse_data* alpha).astype('double')\n",
        "model_1.fit(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1c7d47865d434e8dab872eecbc8bd278",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=45.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ieXuV73lr2P9"
      },
      "source": [
        "#### Converting data into a csv fil for output . "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7V6m2p0r2P9"
      },
      "source": [
        "a=[]                  # declare two empty vectors to store user_id and recommendations\n",
        "b=[]\n",
        "for i in users:               # iterate over every user\n",
        "    top_items = top_recommendations(i)     # get recommendations for each of the users\n",
        "    for j in top_items:\n",
        "        a.append(i)                      # append the top 10 retrieved _items\n",
        "        b.append(j)    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FeXQZBUmr2P9"
      },
      "source": [
        "Now we create empty data frame and load the list values into user_id and columns "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSHFiBTur2P9"
      },
      "source": [
        "column_names = [\"user_id\", \"item_id\"]           \n",
        "                                                  # create empty dataframe with columns\n",
        "df = pd.DataFrame(columns = column_names)       \n",
        "df['user_id'] = a                                 # load list values as column values\n",
        "df['item_id'] = b\n",
        "                       "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Joe4M8ASr2P9"
      },
      "source": [
        "df.to_csv('sample_29.csv', index=False)               # remove index and convert dataframe to csv file  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MV38LW1_r2P9"
      },
      "source": [
        "#### Model 2 : Bayesian Personalized Ranking \n",
        "\n",
        "This famous algorithm is known to work well for implicit data . We again make use of implicit library to call the inbuilt recommender model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvFPkSlVr2P-",
        "colab": {
          "referenced_widgets": [
            "cebdae5050e243109e13a04e0a2692ea"
          ]
        },
        "outputId": "472dea51-96f2-483f-e14a-02dd5234ae3c"
      },
      "source": [
        "model_2= implicit.bpr.BayesianPersonalizedRanking(factors=8, regularization=0.1, iterations=50)\n",
        "alpha = 37\n",
        "data = ( item_sparse_data* alpha).astype('double')      # call function from implicit library and recommend\n",
        "model_2.fit(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cebdae5050e243109e13a04e0a2692ea",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEiNzfyir2P-",
        "outputId": "f958e991-9883-441d-9999-2a69865273d0"
      },
      "source": [
        "#Get Recommendations                              # top 10 recommendations along with score\n",
        "user_id = 0  \n",
        "recommended_2= model_2.recommend(user_id, user_sparse_data)\n",
        "print(recommended_2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(1378, 0.19128324), (1589, 0.18065464), (748, 0.1680759), (127, 0.1592245), (1680, 0.1575718), (1223, 0.15491632), (154, 0.15366045), (196, 0.15098137), (136, 0.15050168), (94, 0.14832266)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5o1GMhKTr2P-"
      },
      "source": [
        "#### Model 3 : Logistic Matrix Factorization\n",
        "We again make use of implicit library to call the inbuilt recommender model that learns probabilistic distribution whether user like it or not .  In our case we have no '0'  values , so there is always some kind of uncertainity."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "2bd84703f66f45c0a2dd9ed7df83ae28"
          ]
        },
        "id": "H5sDnMicr2P-",
        "outputId": "cb44e1d2-af5f-4a38-881d-15f8940882a1"
      },
      "source": [
        "model_3 = implicit.lmf.LogisticMatrixFactorization(factors=20, regularization=0.1, iterations=50)\n",
        "alpha = 40\n",
        "data = ( item_sparse_data* alpha).astype('double')\n",
        "model_3.fit(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2bd84703f66f45c0a2dd9ed7df83ae28",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F90itmwyr2P-",
        "outputId": "851d908c-4e0b-4649-a84f-2e0684110641"
      },
      "source": [
        "#Get Recommendations\n",
        "user_id = 0  \n",
        "recommended_3= model_3.recommend(user_id, user_sparse_data)\n",
        "print(recommended_3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(305, 13.4774685), (440, 12.796539), (256, 12.093139), (959, 11.131193), (151, 10.837425), (989, 10.773423), (1378, 10.5489235), (170, 10.455078), (1615, 10.4301195), (533, 10.392322)]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}