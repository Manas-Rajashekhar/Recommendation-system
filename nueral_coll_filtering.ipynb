{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nueral_coll_filtering.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRpjeeFCGgvO"
      },
      "source": [
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "import torch\r\n",
        "import pandas as pd\r\n",
        "import os\r\n",
        "import random\r\n",
        "import numpy as np                               # loading ll necessary libraries \r\n",
        "import scipy.sparse as sparse\r\n",
        "from scipy.sparse.linalg import spsolve\r\n",
        "from sklearn.preprocessing import MinMaxScaler\r\n",
        "from torch.utils.data import DataLoader, random_split, Dataset\r\n",
        "import torch.optim as optim\r\n",
        "from torch.autograd import Variable\r\n",
        "import torchvision"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MkmmAO9_kM_U"
      },
      "source": [
        "os.chdir(\"/content/sample_data\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwYCpRnHjwNN"
      },
      "source": [
        "# loading datasets\r\n",
        "df_train   = pd.read_csv(\"train_data.csv\")\r\n",
        "df_test = pd.read_csv(\"test_data.csv\")\r\n",
        "#df_test \r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdx0gWFNKUYO"
      },
      "source": [
        "x_users_train = df_train['user_id'].values\r\n",
        "x_items_train = df_train['item_id'].values\r\n",
        "users = torch.tensor(x_users_train,dtype=torch.float32)\r\n",
        "items = torch.tensor(x_items_train,dtype=torch.float32)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SR0JNS6j5JW",
        "outputId": "d32f4d29-a734-4601-cffc-6612b9286a55"
      },
      "source": [
        "users = list(df_train.user_id.unique())              # get a unique list of users and items \r\n",
        "items = list(df_train.item_id.unique())\r\n",
        "no_users = len(users)\r\n",
        "no_items = len(items)\r\n",
        "print(no_users)\r\n",
        "print(no_items)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2239\n",
            "2174\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KY1tHYSDYMBf"
      },
      "source": [
        "class nucf_dataset(Dataset):\r\n",
        "    def __init__(self,filename):\r\n",
        "        file_data = pd.read_csv(\"train_data.csv\")\r\n",
        "        x_users_train = file_data['user_id'].values\r\n",
        "        x_items_train = file_data['item_id'].values\r\n",
        "        y_train = file_data['rating'].values\r\n",
        " \r\n",
        "        self.users = torch.tensor(x_users_train,dtype=torch.float32)\r\n",
        "        self.items = torch.tensor(x_items_train,dtype=torch.float32)\r\n",
        "        self.y = y_train\r\n",
        "\r\n",
        "    def __getitem__(self,idx):\r\n",
        "        return (self.users[idx],self.items[idx]),self.y[idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxLl425Wj7Cj"
      },
      "source": [
        " #Contruct a sparse matrix for our users and items containing number of plays\r\n",
        "user_sparse_data = sparse.csr_matrix((df_train['rating'],(df_train['user_id'],df_train['item_id'])))\r\n",
        "item_sparse_data = sparse.csr_matrix((df_train['rating'],(df_train['item_id'],df_train['user_id'])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMBZSurCwho-"
      },
      "source": [
        "#embeddding dimensions \r\n",
        "embed_dim = 32\r\n",
        "batch_size = 100 \r\n",
        "neurons_mlp = []\r\n",
        "in_size_mlp = 2*embed_dim\r\n",
        "neurons_mlp.append(in_size_mlp)\r\n",
        "output_size = 32\r\n",
        "neurons_mlp.append(output_size)\r\n",
        "\r\n",
        "drop_out_rate = [0.0,0.1,0.2,0.3]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCr9DnGelga6"
      },
      "source": [
        "class NueMf(nn.Module):\r\n",
        "    def __init__(self,no_users,no_items , mlp_layers,embed_dim,neurons):\r\n",
        "        super(NueMf, self).__init__()\r\n",
        "        input_size = neurons[0]\r\n",
        "        output_size = neurons[1]\r\n",
        "        #mf part\r\n",
        "        self.embedding_user_mf = nn.Embedding(no_users, embed_dim)  #embeddding users and items \r\n",
        "\r\n",
        "        self.embedding_item_mf = nn.Embedding(no_items, embed_dim)\r\n",
        "        \r\n",
        "        #mlp part\r\n",
        "        self.embedding_user_mlp = nn.Embedding(no_users, embed_dim)  #embeddding users and items \r\n",
        "\r\n",
        "        self.embedding_item_mlp = nn.Embedding(no_items, embed_dim)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "        self.mlp_layers = nn.Sequential()\r\n",
        "        for i in range(mlp_layers):\r\n",
        "            if i == 0:\r\n",
        "                self.mlp_layers.add_module(\"linear_layer\",nn.Linear(input_size, output_size))\r\n",
        "                self.mlp_layers.add_module(\"relu_layer\",nn.ReLU())\r\n",
        "                self.mlp_layers.add_module(\"drop_out\",nn.Dropout(drop_out_rate[i]))\r\n",
        "            else:\r\n",
        "                self.mlp_layers.add_module(\"linear_layer\",nn.Linear(output_size, output_size))\r\n",
        "                self.mlp_layers.add_module(\"relu_layer\",nn.ReLU())\r\n",
        "                self.mlp_layers.add_module(\"drop_out\",nn.Dropout(drop_out_rate[i]))\r\n",
        "\r\n",
        "        self.output = nn.Linear(output_size + embed_dim, 1)\r\n",
        "\r\n",
        "\r\n",
        "            \r\n",
        "\r\n",
        "        \r\n",
        "    def forward(self,users,items):\r\n",
        "        mf_user_emb = self.embedding_user_mf(users)\r\n",
        "        mf_item_emb = self.embedding_item_mf(items)\r\n",
        "\r\n",
        "        mlp_user_emb = self.embedding_user_mlp(users)\r\n",
        "        mlp_item_emb = self.embedding_item_mlp(items)\r\n",
        "\r\n",
        "        mf_emb_vector = mf_user_emb*mf_item_emb\r\n",
        "        mlp_emb_vector = torch.cat([mlp_user_emb,mlp_item_emb], dim=1)\r\n",
        "        mlp_emb_vector = self.mlp_layers(mlp_emb_vector)\r\n",
        "        \r\n",
        "\r\n",
        "        emb_vector = torch.cat([mf_emb_vector,mlp_emb_vector], dim=1)\r\n",
        "        preds = torch.sigmoid(self.out(emb_vector))\r\n",
        "\r\n",
        "        return preds\r\n",
        "        \r\n",
        "\r\n",
        "model = NueMf(no_users,no_items,3,embed_dim,neurons_mlp)\r\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}